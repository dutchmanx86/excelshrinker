# LLM Excel Analyzer - API Reference

## Quick Start

```python
from llm_analyzer import analyze_from_env

# Ensure OPENAI_API_KEY is set as an environment variable
# export OPENAI_API_KEY='your-key-here'

# Analyze a compressed JSON file and save the output
analysis_markdown = analyze_from_env(
    compressed_file_path='path/to/compressed_output.json',
    output_file_path='path/to/analysis_report.md',
    model="gpt-5"  # Or "gpt-4o", etc.
)

print("Analysis complete. Report saved to analysis_report.md")
```

---

## What This Does

The LLM Excel Analyzer takes the compressed JSON output from the `compression` module and uses a Large Language Model (LLM) to generate a human-readable markdown analysis of the spreadsheet's structure.

**Key functions:**
1.  **Deconstructs Compressed Data**: Interprets the inverted index and format ranges from the JSON input.
2.  **Identifies Logical Sections**: The LLM analyzes the data to identify and group related data into logical sections (e.g., "Income Statement," "Sales Projections").
3.  **Extracts Time Series**: Detects and describes time series data, including date ranges and intervals.
4.  **Generates Structured Documentation**: Produces a markdown report that maps the spreadsheet's layout, making it easy to understand the organization and locate specific data points.

This tool is ideal for quickly understanding the structure of complex financial models or large datasets without manually inspecting the Excel file.

---

## Core Functions

### `analyze_from_env()`

**Recommended entry point.** Analyzes a compressed file using an API key from the `OPENAI_API_KEY` environment variable.

```python
from llm_analyzer import analyze_from_env

analysis = analyze_from_env(
    compressed_file_path="format_detection_compressed.json",
    output_file_path="spreadsheet_analysis.md",
    model="gpt-5"
)
```

**Returns:** `str` - The markdown analysis generated by the LLM.

---

### `analyze_compressed_file()`

Analyzes a compressed JSON file and allows for the API key to be passed directly.

```python
from llm_analyzer import analyze_compressed_file

analysis = analyze_compressed_file(
    compressed_file_path='path/to/compressed.json',
    api_key='your-openai-api-key',
    output_file_path='analysis.md',
    model="gpt-5"
)
```

**Returns:** `str` - The markdown analysis.

---

### `create_llm_analysis()`

Core function that sends the analysis request to the OpenAI API. This provides the most control over the API call.

```python
import json
from llm_analyzer import create_llm_analysis

# Load compressed data from a file
with open('compressed.json', 'r') as f:
    compressed_data = json.load(f)

analysis = create_llm_analysis(
    compressed_json=compressed_data,
    api_key='your-openai-api-key',
    model="gpt-5",
    temperature=0.3
)
```

**Returns:** `str` - The raw markdown string from the API.

---

## Output Format

The generated markdown file has a standardized structure:

### 1. SPREADSHEET OVERVIEW
- A high-level summary including the sheet name, total ranges, and overall date span.

### 2. DATA SECTIONS
- The document is broken down into logical sections identified by the LLM.
- Each section includes details on any associated **time series data**.
- A markdown table details the key data points:
  | Cell Range | Description | Format Type | Date Range | Notes |
  |------------|-------------|-------------|------------|-------|
  | E9:Q9      | "Revenue"   | currency    | Q1 24-Q3 26|       |

### 3. SUMMARY STATISTICS
- A summary of processing stats, including cells analyzed, format breakdown, and more.

---

## Configuration & Performance

- **Model Selection**: The `model` parameter can be set to `"gpt-5"`, `"gpt-4o"`, or other compatible models. Note that `gpt-5` is optimized for complex reasoning but may have longer processing times.
- **Temperature**: For models other than `gpt-5`, the `temperature` can be adjusted. A lower value (e.g., `0.3`) is recommended for more deterministic, factual output.
- **Timeout**: The API call includes a 10-minute timeout (`600s`) to accommodate larger analysis tasks.
- **Tokens**: The `max_completion_tokens` is set to a high value (64,000) to allow for detailed analysis and prevent truncation.

---

## Error Handling

The module will raise specific errors for common issues:

- `ValueError`: If `OPENAI_API_KEY` is not set when using `analyze_from_env`.
- `ImportError`: If the `openai` package is not installed.
- `Exception`: For general API call failures, including network issues or invalid keys. The error message from the OpenAI API will be included.

---

## Installation

```bash
pip install openai
```

---

## Related Documentation

- [Boundary Detector API](../boundary_detector/API_REFERENCE.md)
- [Compression Tools API](../compression/API_REFERENCE.md)